{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c9daa20-4463-4c29-86d7-e8b55a836d6a",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-11e06e57608fe1f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Проект по курсу \"Рекомендательные системы\"\n",
    "  \n",
    "Правила заполнения ноутбуков на авто-проверку:\n",
    "- повторить окружение преподавателя\n",
    "Python 3.13.0\n",
    "```bash\n",
    "pip install implicit==0.7.2 \"rectools[all]==0.17.0\" pandas==2.3.3 numpy==2.3.3 scipy==1.16.2  requests==2.32.5 catboost==1.2.8 scikit-learn==1.7.2\n",
    "```\n",
    "- все решение должно полностью помещаться в функцию solution(смотри пример). Если вы хотите реализовать дополнительные функции - поместите их в область видимости soluition. Нельзя использовать дополнительные файлы.\n",
    "- не добавлять новые импорты и не использовать дополнительные библиотеки. В противном случае ноутбук не пройдёт проверку и получит `0` баллов\n",
    "- не добавлять аргументов в solution\n",
    "- писать код только между # CODE BEGIN и # CODE END\n",
    "- не менять код преподавателя\n",
    "- не добавлять новые ячейки\n",
    "- следить, чтобы не было warning - они автоматом фейлят задание\n",
    "- перед сдачей проверить, что весь ноутбук прогоняется от начала до конца и все тесты проходят\n",
    "- data_path должен браться из переменной окружения как в коде ниже\n",
    "- Код должен выполняться за разумное время - ограничение 20 мин на 4 CPU и 16 Gb RAM без GPU. Не нужно ставить огромное количество эпох.\n",
    "- Постарайтесь максимально зафиксировать сиды, чтобы не было сюрпризов во время автоматической проверки. В случае, если решение выдает разное качество при разных запусках, то в зачет идет то значение, которое получилось при автоматической проверке.\n",
    "\n",
    "\n",
    "В данном проекте вам возможно захочется подбирать гипер-параметры моделей. Писать код для подбора гипер-параметров, использовать optuna и т.п. рекомендуем в отдельном ноутбуке.\n",
    "\n",
    "Библиотеки implicit и lightfm не фиксируют random state при num_threads > 1. Если результат работы модели не сильно превышает  необходимый порог и рандом может опустить его ниже требуемого уровня, рекомендуем продолжить повышение качества модели: тюнинг гипер-параметров, подбор фичей, подбор метода обработки датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77c2daf",
   "metadata": {},
   "source": [
    "# Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5661b22c",
   "metadata": {},
   "source": [
    "Вам предлагается реализовать рекомендательную систему для фильмов KION.\n",
    "Решение должно быть полностью упаковано в функцию solution. Качество будет проверяться с помощью метрики MAP@10 на отложенной неделе. Итоговый бал определеятся функцией scorer - вы можете посмотреть его сразу, но если модель не подразумевает фиксирование random state, то после прогона автоматической системой результат может немного отличаться.\n",
    "\n",
    "В качестве примера реализована базовая рекомендательная система на основе ease. Ваша задача - улучшить эту систему.\n",
    "\n",
    "Чтобы решение отрабатывало быстрее будем использовать 10% от общего числа пользователей.\n",
    "\n",
    "В случае, если в вашем решении будет найден Hardcode элементов тестового датафрейма - работа будет аннулирована.\n",
    "\n",
    "Напоминаю, что для зачета по курсу нужно набрать в сумме с доп баллами и первым дз 60 баллов.\n",
    "\n",
    "Успехов!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c3166e",
   "metadata": {},
   "source": [
    "Подсказки:\n",
    "- Можно посмотреть документацию rectools\n",
    "- Можно поссмотреть ноутбуки с семинаров и предыдущую версию проекта\n",
    "- Не стесняйтесь добавлять фичи в ранжирование\n",
    "- Скорее всего вам понадобятся как отбор кандидатов, так и ранжирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d49cde7-2156-468a-b3e2-e8467e241cf8",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1891eaa3c13c8609",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Импорты и данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "724a1ce6-1a8d-4f7a-95df-17021d831dfc",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6e865769efae1be6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.13.0\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b118efea-a833-402f-9048-562d79dcea42",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-49e3b781726cecc9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7.2\n",
      "0.17.0\n",
      "2.3.3\n",
      "2.3.3\n",
      "1.16.2\n",
      "2.32.5\n",
      "1.2.8\n",
      "1.7.2\n"
     ]
    }
   ],
   "source": [
    "# Убедитесь, что вы не добавляете новые импорты в ноутбук. Решение должно быть ограничено данными библиотеками\n",
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import implicit\n",
    "import rectools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import requests\n",
    "import catboost\n",
    "import sklearn\n",
    "\n",
    "from rectools import models\n",
    "from rectools import dataset\n",
    "from rectools import metrics\n",
    "\n",
    "print(implicit.__version__)\n",
    "print(rectools.__version__)\n",
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "print(scipy.__version__)\n",
    "print(requests.__version__)\n",
    "print(catboost.__version__)\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3591f25-aedf-42b5-8b65-1f02e51d3020",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1ebdc35957207757",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<threadpoolctl.threadpool_limits at 0x30e363c50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "# For implicit ALS\n",
    "import threadpoolctl\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "threadpoolctl.threadpool_limits(1, \"blas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0265ea46-e840-452d-b43b-343cbb7eb160",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-42bc3babcb8ca15b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Если у вас нет данных, то используйте закомментированный код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f385743a-3642-4152-82bd-e4eca87130bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.auto import tqdm\n",
    "# import zipfile as zf\n",
    "\n",
    "# url = 'https://github.com/irsafilo/KION_DATASET/raw/f69775be31fa5779907cf0a92ddedb70037fb5ae/data_original.zip'\n",
    "\n",
    "# req = requests.get(url, stream=True)\n",
    "\n",
    "# with open('kion.zip', 'wb') as fd:\n",
    "#     total_size_in_bytes = int(req.headers.get('Content-Length', 0))\n",
    "#     progress_bar = tqdm(desc='kion dataset download', total=total_size_in_bytes, unit='iB', unit_scale=True)\n",
    "#     for chunk in req.iter_content(chunk_size=2 ** 20):\n",
    "#         progress_bar.update(len(chunk))\n",
    "#         fd.write(chunk)\n",
    "\n",
    "# files = zf.ZipFile('kion.zip', 'r')\n",
    "# files.extractall()\n",
    "# files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b128d75-5970-42c0-b89e-1d48c1688936",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.environ.get(\"DATA_PATH\")\n",
    "if data_path is None:\n",
    "    data_path = \"data_original\"  # ваш путь к данным до папки data_original включительно (поменяйте при необходимости)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e1b9888-cdc7-47a3-9162-a1ae7de7144e",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a1b82be4e2c39f91",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(440150, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>weight</th>\n",
       "      <th>watched_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>791466</td>\n",
       "      <td>8199</td>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>713</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>988709</td>\n",
       "      <td>7571</td>\n",
       "      <td>2021-07-07</td>\n",
       "      <td>6558</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>927973</td>\n",
       "      <td>9617</td>\n",
       "      <td>2021-06-19</td>\n",
       "      <td>8422</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>505244</td>\n",
       "      <td>15297</td>\n",
       "      <td>2021-08-15</td>\n",
       "      <td>15991</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>81786</td>\n",
       "      <td>2616</td>\n",
       "      <td>2021-07-24</td>\n",
       "      <td>41422</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  item_id   datetime  weight  watched_pct\n",
       "10   791466     8199 2021-07-27     713          9.0\n",
       "11   988709     7571 2021-07-07    6558        100.0\n",
       "18   927973     9617 2021-06-19    8422        100.0\n",
       "22   505244    15297 2021-08-15   15991         63.0\n",
       "28    81786     2616 2021-07-24   41422         90.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv(os.path.join(data_path, \"users.csv\"))\n",
    "items = pd.read_csv(os.path.join(data_path, \"items.csv\"))\n",
    "\n",
    "users = users.sample(frac=0.1, random_state=42)\n",
    "\n",
    "interactions = (\n",
    "    pd.read_csv(os.path.join(data_path, \"interactions.csv\"), parse_dates=[\"last_watch_dt\"])\n",
    "    .rename(columns={'total_dur': rectools.Columns.Weight,\n",
    "                     'last_watch_dt': rectools.Columns.Datetime})\n",
    ")\n",
    "\n",
    "\n",
    "interactions = interactions[interactions[\"user_id\"].isin(users[\"user_id\"])]\n",
    "\n",
    "\n",
    "print(interactions.shape)\n",
    "interactions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecfa3e3e-477e-449c-863f-83decd2a608f",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-457223d68ac460f6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24771\n",
      "9099\n"
     ]
    }
   ],
   "source": [
    "N_DAYS = 7\n",
    "\n",
    "max_date = interactions['datetime'].max()\n",
    "train = interactions[(interactions['datetime'] <= max_date - pd.Timedelta(days=N_DAYS))]\n",
    "test = interactions[(interactions['datetime'] > max_date - pd.Timedelta(days=N_DAYS))]\n",
    "\n",
    "catalog = train[rectools.Columns.Item].unique()\n",
    "\n",
    "test_users = test[rectools.Columns.User].unique()\n",
    "cold_users = set(test_users) - set(train[rectools.Columns.User])\n",
    "test.drop(test[test[rectools.Columns.User].isin(cold_users)].index, inplace=True)\n",
    "hot_users = test[rectools.Columns.User].unique()\n",
    "print(test.shape[0])\n",
    "print(test[rectools.Columns.User].nunique())\n",
    "\n",
    "def scorer(map: float):\n",
    "    print(f\"Ваш MAP: {map}\")\n",
    "    UPPER_BOUND = 0.089\n",
    "    LOWER_BOUND = 0.071\n",
    "    score = int(min(max( (map - LOWER_BOUND) / (UPPER_BOUND - LOWER_BOUND), 0), 1) * 80)\n",
    "    print(f\"Ваш итоговый балл: {score}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d2619d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution(train: pd.DataFrame, users: pd.DataFrame, items: pd.DataFrame):\n",
    "    #  CODE BEGIN\n",
    "    from implicit.als import AlternatingLeastSquares\n",
    "    \n",
    "    # Optimize weights based on watched_pct - give more weight to fully watched content\n",
    "    train[rectools.Columns.Weight] = np.where(train['watched_pct'] >= 90, 15, \n",
    "                                              np.where(train['watched_pct'] >= 70, 8,\n",
    "                                              np.where(train['watched_pct'] >= 40, 4,\n",
    "                                              np.where(train['watched_pct'] >= 15, 2, 1))))\n",
    "    \n",
    "    # Construct dataset\n",
    "    dataset = rectools.dataset.Dataset.construct(train)\n",
    "    \n",
    "    # Model 1: ALS with optimized parameters\n",
    "    als_model = rectools.models.ImplicitALSWrapperModel(\n",
    "        model=AlternatingLeastSquares(\n",
    "            factors=150,\n",
    "            iterations=20,\n",
    "            regularization=0.01,\n",
    "            random_state=42,\n",
    "            alpha=1.0\n",
    "        )\n",
    "    )\n",
    "    als_model.fit(dataset)\n",
    "    \n",
    "    # Model 2: EASE\n",
    "    ease_model = rectools.models.EASEModel(regularization=500)\n",
    "    ease_model.fit(dataset)\n",
    "    \n",
    "    # Model 3: PureSVD\n",
    "    svd_model = rectools.models.PureSVDModel(factors=150)\n",
    "    svd_model.fit(dataset)\n",
    "    \n",
    "    # Generate candidates from all models\n",
    "    K_RECS = 30\n",
    "    \n",
    "    als_recs = als_model.recommend(users=hot_users, dataset=dataset, k=K_RECS, filter_viewed=True)\n",
    "    ease_recs = ease_model.recommend(users=hot_users, dataset=dataset, k=K_RECS, filter_viewed=True)\n",
    "    svd_recs = svd_model.recommend(users=hot_users, dataset=dataset, k=K_RECS, filter_viewed=True)\n",
    "    \n",
    "    # Add model identifiers\n",
    "    als_recs['model'] = 'als'\n",
    "    ease_recs['model'] = 'ease'\n",
    "    svd_recs['model'] = 'svd'\n",
    "    \n",
    "    # Combine all recommendations\n",
    "    all_recs = pd.concat([als_recs, ease_recs, svd_recs])\n",
    "    \n",
    "    # Normalize scores within each model\n",
    "    all_recs['score_norm'] = all_recs.groupby(['user_id', 'model'])['score'].transform(\n",
    "        lambda x: (x - x.min()) / (x.max() - x.min() + 1e-10)\n",
    "    )\n",
    "    \n",
    "    # Aggregate scores with weighted average (ALS has higher weight)\n",
    "    model_weights = {'als': 0.5, 'ease': 0.3, 'svd': 0.2}\n",
    "    all_recs['weighted_score'] = all_recs.apply(lambda row: row['score_norm'] * model_weights[row['model']], axis=1)\n",
    "    \n",
    "    # Group by user and item, sum weighted scores\n",
    "    final_scores = (all_recs.groupby(['user_id', 'item_id'])\n",
    "                    .agg({'weighted_score': 'sum', 'score': 'max'})\n",
    "                    .reset_index())\n",
    "    \n",
    "    # Sort by weighted score and select top 10 per user\n",
    "    final_recs = (final_scores\n",
    "                  .sort_values(['user_id', 'weighted_score'], ascending=[True, False])\n",
    "                  .groupby('user_id')\n",
    "                  .head(10)\n",
    "                  .reset_index(drop=True))\n",
    "    \n",
    "    final_recs['rank'] = final_recs.groupby('user_id').cumcount() + 1\n",
    "    final_recs = final_recs.rename(columns={'weighted_score': 'score'})\n",
    "    final_recs = final_recs[['user_id', 'item_id', 'score', 'rank']]\n",
    "    \n",
    "    #  CODE END\n",
    "    return final_recs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e5101e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.4 s, sys: 1.92 s, total: 52.4 s\n",
      "Wall time: 52.4 s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mrecos = solution(train.copy(), users.copy(), items.copy())\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mscorer(rectools.metrics.MAP(10).calc(recos, test))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.0/envs/aaa/lib/python3.13/site-packages/IPython/core/interactiveshell.py:2565\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2563\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2564\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2565\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2568\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2569\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2570\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.0/envs/aaa/lib/python3.13/site-packages/IPython/core/magics/execution.py:1452\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1450\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m interrupt_occured:\n\u001b[32m   1451\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exit_on_interrupt \u001b[38;5;129;01mand\u001b[39;00m captured_exception:\n\u001b[32m-> \u001b[39m\u001b[32m1452\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m captured_exception\n\u001b[32m   1453\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1454\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.0/envs/aaa/lib/python3.13/site-packages/IPython/core/magics/execution.py:1421\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m expr_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1420\u001b[39m         code_2 = \u001b[38;5;28mself\u001b[39m.shell.compile(expr_val, source, \u001b[33m'\u001b[39m\u001b[33meval\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1421\u001b[39m         out = \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcode_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_ns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1423\u001b[39m     captured_exception = e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:2\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.0/envs/aaa/lib/python3.13/site-packages/rectools/metrics/ranking.py:63\u001b[39m, in \u001b[36m_RankingMetric.calc\u001b[39m\u001b[34m(self, reco, interactions)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcalc\u001b[39m(\u001b[38;5;28mself\u001b[39m, reco: pd.DataFrame, interactions: pd.DataFrame) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m     48\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[33;03m    Calculate metric value.\u001b[39;00m\n\u001b[32m     50\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m \u001b[33;03m        Value of metric (average between users).\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     per_user = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcalc_per_user\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreco\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minteractions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m per_user.mean()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.0/envs/aaa/lib/python3.13/site-packages/rectools/metrics/ranking.py:258\u001b[39m, in \u001b[36mMAP.calc_per_user\u001b[39m\u001b[34m(self, reco, interactions)\u001b[39m\n\u001b[32m    255\u001b[39m     is_debiased = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    257\u001b[39m \u001b[38;5;28mself\u001b[39m._check(reco, interactions=interactions)\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m merged_reco = \u001b[43mmerge_reco\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreco\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minteractions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    259\u001b[39m fitted = \u001b[38;5;28mself\u001b[39m.fit(merged_reco, k_max=\u001b[38;5;28mself\u001b[39m.k)\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.calc_per_user_from_fitted(fitted, is_debiased)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.0/envs/aaa/lib/python3.13/site-packages/rectools/metrics/base.py:99\u001b[39m, in \u001b[36mmerge_reco\u001b[39m\u001b[34m(reco, interactions)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmerge_reco\u001b[39m(reco: pd.DataFrame, interactions: pd.DataFrame) -> pd.DataFrame:\n\u001b[32m     82\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[33;03m    Merge recommendation table with interactions table.\u001b[39;00m\n\u001b[32m     84\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     95\u001b[39m \u001b[33;03m        Result of merging.\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     97\u001b[39m     merged = pd.merge(\n\u001b[32m     98\u001b[39m         interactions.reindex(columns=Columns.UserItem),\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m         \u001b[43mreco\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mColumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mUserItem\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mColumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mRank\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    100\u001b[39m         on=Columns.UserItem,\n\u001b[32m    101\u001b[39m         how=\u001b[33m\"\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    102\u001b[39m     )\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m merged\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.0/envs/aaa/lib/python3.13/site-packages/pandas/core/frame.py:5400\u001b[39m, in \u001b[36mDataFrame.reindex\u001b[39m\u001b[34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[39m\n\u001b[32m   5381\u001b[39m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[32m   5382\u001b[39m     NDFrame.reindex,\n\u001b[32m   5383\u001b[39m     klass=_shared_doc_kwargs[\u001b[33m\"\u001b[39m\u001b[33mklass\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   5398\u001b[39m     tolerance=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5399\u001b[39m ) -> DataFrame:\n\u001b[32m-> \u001b[39m\u001b[32m5400\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5403\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5404\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5406\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5407\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5411\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.0/envs/aaa/lib/python3.13/site-packages/pandas/core/generic.py:5632\u001b[39m, in \u001b[36mNDFrame.reindex\u001b[39m\u001b[34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[39m\n\u001b[32m   5629\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._reindex_multi(axes, copy, fill_value)\n\u001b[32m   5631\u001b[39m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5632\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reindex_axes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5633\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[32m   5634\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mreindex\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.0/envs/aaa/lib/python3.13/site-packages/pandas/core/generic.py:5655\u001b[39m, in \u001b[36mNDFrame._reindex_axes\u001b[39m\u001b[34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[39m\n\u001b[32m   5652\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   5654\u001b[39m ax = \u001b[38;5;28mself\u001b[39m._get_axis(a)\n\u001b[32m-> \u001b[39m\u001b[32m5655\u001b[39m new_index, indexer = \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5656\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\n\u001b[32m   5657\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5659\u001b[39m axis = \u001b[38;5;28mself\u001b[39m._get_axis_number(a)\n\u001b[32m   5660\u001b[39m obj = obj._reindex_with_indexers(\n\u001b[32m   5661\u001b[39m     {axis: [new_index, indexer]},\n\u001b[32m   5662\u001b[39m     fill_value=fill_value,\n\u001b[32m   5663\u001b[39m     copy=copy,\n\u001b[32m   5664\u001b[39m     allow_dups=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   5665\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.0/envs/aaa/lib/python3.13/site-packages/pandas/core/indexes/base.py:4436\u001b[39m, in \u001b[36mIndex.reindex\u001b[39m\u001b[34m(self, target, method, level, limit, tolerance)\u001b[39m\n\u001b[32m   4433\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot handle a non-unique multi-index!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4434\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_unique:\n\u001b[32m   4435\u001b[39m     \u001b[38;5;66;03m# GH#42568\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4436\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4437\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4438\u001b[39m     indexer, _ = \u001b[38;5;28mself\u001b[39m.get_indexer_non_unique(target)\n",
      "\u001b[31mValueError\u001b[39m: cannot reindex on an axis with duplicate labels"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "recos = solution(train.copy(), users.copy(), items.copy())\n",
    "scorer(rectools.metrics.MAP(10).calc(recos, test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
